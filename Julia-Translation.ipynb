{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEIR-model-Stockholm-Julia\n",
    "I got tired of waiting for the R code to execute, so I decided to rewrite the initial parts of [the script](https://github.com/FohmAnalys/SEIR-model-Stockholm/commit/8c79ba30ea154ff47f1a9676a8f68c0d3b84793c#diff-824cda0829d07b1639809e1579eb586c) in Julia, with multithreading in order to speed things up. With a typical quad-core, the speed is roughly on the order of $10^{2.5}$ times that of the R code on the second run. Going from 30min to 10s allows for more convenient exploration. Note that the JIT-compilation will cause the first run to be significantly slower. Note that `@everywhere` is required for code to be run on all threads.\n",
    "\n",
    "The solutions found are not always exactly the same as the R equivalent, but in some cases RSS (the loss function) is lower, which could indicate a better fit.\n",
    "\n",
    "I do not guarantee that any of the code below will yield the same results as the original code. Use at your own risk.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, DataFrames, Distributions;\n",
    "# Try installing the Python xlrd package if ExcelFiles won't run.\n",
    "using RData, FileIO, CSVFiles, ExcelFiles;\n",
    "import Random.rand, CSV;\n",
    "import Calculus.hessian, Statistics.mean, LinearAlgebra.Diagonal;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multithreading\n",
    "using Distributed;\n",
    "\n",
    "# Set the number of workers to equal the number of CPU threads.\n",
    "# This will likely fail if you are running on MyBinder.\n",
    "if length(workers())>1 rmprocs(workers());end;addprocs();\n",
    "\n",
    "# Import the following packages into the threads.\n",
    "@everywhere using Optim, OrdinaryDiffEq, Dates;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will update Project.toml with NewPackage for MyBinder.\n",
    "# Run before commiting if you've installed a new package.\n",
    "#import Pkg;Pkg.activate(\"\");Pkg.add(\"NewPackage\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation helpers\n",
    "Makes translation from R easier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that make translation from R a bit easier...\n",
    "@everywhere function runif(c::Int, min::Real, max::Real)::Vector{Float64}\n",
    "    return rand(c) .* (max-min) .+ min;\n",
    "    end;\n",
    "\n",
    "# For quick date conversion\n",
    "function dayToDate(day::Int)::Date\n",
    "    return Dates.Day(day) + Dates.Date(\"2019-12-31\");\n",
    "    end;\n",
    "\n",
    "@everywhere function dateToDay(date::Date)::Int\n",
    "    return Dates.Day(date - Dates.Date(\"2019-12-31\")).value;\n",
    "    end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From a sample x, calculate a credibility interval with wanted level. \n",
    "function CRI(x::AbstractVector{Float64}; level::Float64 = 0.95)::Tuple{Float64, Float64}\n",
    "    local n::Int, L::Float64, U::Float64, resL::Float64, resU::Float64;\n",
    "    n = length(x);\n",
    "    L = (1 - level) / 2;\n",
    "    U = 1 - (1 - level) / 2;\n",
    "    x = sort(x);\n",
    "    #@ Added rounding here.\n",
    "    resL = x[Int(round(n * L))];\n",
    "    resU = x[Int(round(n * U))];\n",
    "    #names(resL) <- paste((L * 100), \"%\") \n",
    "    #names(resU) <- paste((U * 100), \"%\")\n",
    "\n",
    "    return (resL, resU);\n",
    "    end;\n",
    "\n",
    "function CRI_90_low(x::AbstractVector{Float64}) return CRI(x, level = 0.9)[1]; end;\n",
    "function CRI_90_up(x::AbstractVector{Float64})  return CRI(x, level = 0.9)[2]; end;\n",
    "function CRI_95_low(x::AbstractVector{Float64}) return CRI(x, level = 0.95)[1]; end;\n",
    "function CRI_95_up(x::AbstractVector{Float64})  return CRI(x, level = 0.95)[2]; end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Currently just uses the default directories for loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin\n",
    "    local rd, rp, r_name, region_namn, df_riket;\n",
    "\n",
    "    # Take out population\n",
    "    rd = load(File(DataFormat{:RData},\"Data/Sverige_population_2019.Rdata\"))\n",
    "\n",
    "    # rp is a DataFrame that is turned into Region_population\n",
    "    rp          = rd[\"dat_pop_region_totalt\"];\n",
    "    rp[!, :Pop] = Int.(rp[!, :Pop]);\n",
    "    r_name      = rp[!, :ARegion];\n",
    "\n",
    "    region_namn = replace.(r_name, \"s län\" => \"\");\n",
    "    region_namn = replace.(region_namn, \" län\" => \"\");\n",
    "    region_namn = region_namn[region_namn .!= \"Riket\"];\n",
    "\n",
    "    rp[!, :ARegion] = region_namn;\n",
    "\n",
    "    df_riket = DataFrame(ARegion = \"Riket\", Pop = 2385128+5855459+2078886);\n",
    "    \n",
    "    global const Stockholm_Data = rename(CSV.read(\"Data/Data_2020-04-10Ny.txt\", delim=\" \", header = true), [:Datum, :Incidens]);\n",
    "    global const Region_population = vcat(rp, df_riket);\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables and constants\n",
    "A fair amount of variables that were local in the original code have been changed into global constants, as they shouldn't be changing. Some global vars are defined at analysis.\n",
    "\n",
    "### Parameters\n",
    "Feel free to redefine these at the analysis stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rate of leaving incubation\n",
    "eta_value    = 1/5.1;\n",
    "# Rate of recovery\n",
    "gammaD_value = 1/5;\n",
    "\n",
    "## Tolerance for ode and optimisation. \n",
    "Atol = 1e-8;\n",
    "Rtol = 1e-10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previously local variables\n",
    "Constants that used to be a part of `Estimate_function_Stockholm`, and its subfunctions. Note that the variable called `Day` in the R script has been renamed to `Dag`, as not to conflict with the `Dates.Day` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population of Stockholm\n",
    "const N = Region_population[Region_population[!, :ARegion] .== \"Stockholm\", 2][1];\n",
    "\n",
    "## Daily incidence reported cases and their dates\n",
    "const Incidence = Stockholm_Data[!, :Incidens];\n",
    "const Datum = Date.(Stockholm_Data[!, :Datum]);\n",
    "const Dag = dateToDay.(Datum);\n",
    "# Used by the ode solver\n",
    "const DagspanF = (Float64(minimum(Dag)), Float64(maximum(Dag)));\n",
    "\n",
    "const dayatmonth = [1,31,29,31,30,31,30,31,31,30,31,30,31];\n",
    "const dayatyear = [cumsum(dayatmonth)...];\n",
    "const Namedate = [[Dates.Day(d) + Date(\"2019-12-31\") for d in dayatyear]...];\n",
    "\n",
    "const Opt_par_names = [\"delta\",\"epsilon\",\"theta\"];\n",
    "\n",
    "## assumption on initial number of infected. \n",
    "## In our main analysis we start with 1 infectious individual at t_0 = 17th Ferbruary \n",
    "# init <- c(S = N - Incidence[1]*(1 + (1-p_symp)/p_symp), E = 0, I_symp = Incidence[1], I_asymp = Incidence[1]*(1-p_symp)/p_symp , R = 0)\n",
    "const init = (S = N-Incidence[1], E = 0, I_symp = Incidence[1], I_asymp = 0 , R = 0);\n",
    "const initfa = [Float64.(values(init))...];\n",
    "\n",
    "## Dagen för \"jobba hemma\"\n",
    "## 16 Mars 2020 = 76\n",
    "## Previously a part of RSS.\n",
    "@everywhere const t_b = dateToDay(Dates.Date(\"2020-03-15\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent functions\n",
    "Aka. functions that are not reliant on local variables in `Estimate_function_Stockholm`.\n",
    "\n",
    "Beta, aka. the infectivity is approximated as the following:\n",
    "\n",
    "$\\beta(t, \\delta, \\epsilon, \\theta) = \\theta\\bigg(\\frac{1-\\delta}{1+e^{\\epsilon*(-(t-t_b))}} + \\delta\\bigg)$\n",
    "\n",
    "The basic reproductive number $R_0$ is normally calculated as the following, but here we also have corrections for the different infectivity of asymptomatic patients.\n",
    "\n",
    "$R_0 = \\frac{\\beta}{\\gamma}$\n",
    "\n",
    "These functions only accept Float64 for performance reasons. Not even sure if this makes a difference, but one can change Float64 to Real if one wants to be able to hand other numbers to these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to create guesses for the optimisation\n",
    "## The range of the guesses can be changed, \n",
    "## these are good for the specific dates and parameter combinations of p_symp and p_lower_inf\n",
    "@everywhere function Guesses()::Vector{Float64}\n",
    "    u_d = runif(1, 0.05, 0.6)[1] # guess for delta \n",
    "    u_e = runif(1,-0.6, 0)[1]    # guess for epsilon\n",
    "    u_t = runif(1, 0, 15)[1]     # guess for theta\n",
    "    return [u_d, u_e, u_t];\n",
    "    end;\n",
    "\n",
    "## The time-dependent infectivity rate\n",
    "@everywhere function beta_decrease(t::Float64, delta::Float64, epsilon::Float64, theta::Float64)::Float64\n",
    "    global t_b;\n",
    "    return ((1-delta)/(1+exp(epsilon*(-(t-t_b)))) + delta)* theta;\n",
    "    end;\n",
    "\n",
    "# Fallback. Only to be used in the main thread.\n",
    "# TODO check if this improves performance. The compiler is rather smart, so it may be able to handle\n",
    "#      having the main function only have ::Real as arguments.\n",
    "function beta_decrease(t::Real, delta::Real, epsilon::Real, theta::Real)::Float64\n",
    "    return beta_decrease(Float64.([t, delta, epsilon, theta])...);\n",
    "    end;\n",
    "\n",
    "function beta_inverse(gamma::Real, delta::Real, epsilon::Real, theta::Real; planb::T = -Inf)::Union{T, Float64} where T <: Real\n",
    "    global t_b; # dagen för jobba hemma\n",
    "    local a::Float64 = ((1-delta)/((gamma/theta) - delta))-1;\n",
    "    return (a > 0) ? -(log(a)/epsilon)+t_b : planb;\n",
    "    end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function\n",
    "Note that the means of optimization differs from the R implementation, as there are parts of that, specifically the things stored in the `conl` variable that I do not know how to implement with the Optim.jl package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function Estimate_function_Stockholm(;\n",
    "        p_symp::Real = 0.5,\n",
    "        p_lower_inf::Real = 0.5,\n",
    "        gammaD::Real = gammaD_value,\n",
    "        eta::Real = eta_value,\n",
    "        iter::Int = 50,\n",
    "    )\n",
    "\n",
    "    global N, Incidence, Datum, Dag, dayatmonth, dayatyear, Namedate, Opt_par_names;\n",
    "\n",
    "    ## The SEIR model.\n",
    "    function model!(du::Vector{Float64}, state::Vector{Float64}, parameters::Vector{Float64}, time::Float64)\n",
    "        # S       <- state[1] # susceptibles\n",
    "        # E       <- state[2] # latent/exposed but not infectious\n",
    "        # I_symp  <- state[3] # infected who get reported\n",
    "        # I_asymp <- state[4] # infected who remain non-reported\n",
    "        # R       <- state[5] # recovered/immune\n",
    "        \n",
    "        # No need to specify types for these vars. The compiler can infer it, as long as the arg types are non-ambiguous\n",
    "        # @views does not speed up this to any measurable extent.\n",
    "        local S, E, I_symp, I_asymp, R = state;\n",
    "        local delta, epsilon, theta = parameters;\n",
    "\n",
    "        du[1] = -beta_decrease(time, delta, epsilon, theta) * S * I_symp/N - p_lower_inf*beta_decrease(time, delta, epsilon, theta) * S * I_asymp/N\n",
    "        du[2] = beta_decrease(time, delta, epsilon, theta) * S * I_symp/N + p_lower_inf*beta_decrease(time, delta, epsilon, theta) * S * I_asymp/N - eta*E\n",
    "        du[3] = p_symp * eta * E      - gammaD * I_symp\n",
    "        du[4] = (1 - p_symp)* eta * E - gammaD * I_asymp\n",
    "        du[5] = gammaD * (I_symp + I_asymp)\n",
    "        end;\n",
    "\n",
    "    function RSS(parameters::Vector{Float64})\n",
    "        \n",
    "        # Beta_max = theta. Beta_min = theta*delta. param order = delta, epsilon, theta\n",
    "        # One could argue that we should check that epsilon is negative as well.\n",
    "        # if the infectivity is negative, throw away guess\n",
    "        if(parameters[2] > 0 || parameters[3] < 0 || parameters[1] < 0)\n",
    "            return 10^12;\n",
    "        else\n",
    "            # choose tolerance atol and rtol\n",
    "            local out = solve(ODEProblem(model!, initfa, DagspanF, parameters), Tsit5(), reltol=Rtol, abstol=Atol);\n",
    "\n",
    "            # I tried making this more elegant, but it self-referenced when using repeat, which caused everything to become fit_I_asymp\n",
    "            #local fit_S::Vector{Float64} = Vector{Float64}(undef, length(Dag));\n",
    "            local fit_E::Vector{Float64} = Vector{Float64}(undef, length(Dag));\n",
    "            #local fit_I_symp::Vector{Float64} = Vector{Float64}(undef, length(Dag));\n",
    "            #local fit_I_asymp::Vector{Float64} = Vector{Float64}(undef, length(Dag));\n",
    "            local fitted_incidence::Vector{Float64} = Vector{Float64}(undef, length(Dag));\n",
    "\n",
    "            for (i, d) in enumerate(Dag)\n",
    "                fit_E[i] = out(d)[2];\n",
    "                # Not used, hence removed for SPEED.\n",
    "                #fit_S[i] = out(d)[1];\n",
    "                #fit_I_symp[i] = out(d)[3];\n",
    "                #fit_I_asymp[i] = out(d)[4];\n",
    "                end;\n",
    "            \n",
    "            fitted_incidence = eta * p_symp * fit_E;\n",
    "            # Old, faulty version. Does not take incubation into consideration.\n",
    "            #fitted_incidence = beta_decrease.(Dag, delta = parameters[1], epsilon = parameters[2],  theta = parameters[3]) .* fit_S .* fit_I_symp ./ N;\n",
    "\n",
    "            return sum((Incidence - fitted_incidence).^ 2);\n",
    "            #return DataFrame(T=Dag, S=fit_S, Is=fit_I_symp, Ia=fit_I_asymp);\n",
    "            end;\n",
    "        end;\n",
    "    \n",
    "    ## The time-dependent basic reproductive number\n",
    "    function Basic_repr(t::Real, delta::Real, epsilon::Real, theta::Real, gamma::Real)::Float64\n",
    "        return p_symp * beta_decrease(t, delta, epsilon, theta) / gamma + (1 - p_symp) * p_lower_inf * beta_decrease(t, delta, epsilon, theta) / gamma;\n",
    "        end;\n",
    "    \n",
    "    # I don't know how to properly adjust the options to resemble the original code.\n",
    "    # Specifically I don't know how feature scaling works with Optim.jl\n",
    "    local conl::Optim.Options, Opt, optAlg, beta; \n",
    "    conl = Optim.Options(iterations = 1000, g_abstol = Atol, g_reltol = Rtol);\n",
    "    Opt    = (x_converged = false,);\n",
    "    optAlg = NelderMead();\n",
    "\n",
    "    Opt = optimize(RSS, Guesses(), optAlg, conl);\n",
    "    \n",
    "    #@ Run until convergence. Should perhaps be multi-threaded.\n",
    "    while(!(Opt.x_converged || Opt.f_converged || Opt.g_converged))\n",
    "        Opt = optimize(RSS, Guesses(), optAlg, conl);\n",
    "    end;\n",
    "    \n",
    "    local futures = Vector{Future}(undef, iter);\n",
    "    # Brute-force approach.\n",
    "    for i = 1:iter\n",
    "        futures[i] = @spawnat :any try\n",
    "            return optimize(RSS, Guesses(), optAlg, conl);\n",
    "            catch; #catch e; return e; for debugging\n",
    "            return false\n",
    "        end;\n",
    "    end;\n",
    "    \n",
    "    for i = 1:iter\n",
    "        Opt2 = fetch(futures[i]);\n",
    "        if(Opt2 != false && (Opt2.x_converged || Opt2.f_converged || Opt2.g_converged))\n",
    "            if(Opt2.minimum < Opt.minimum && Opt2.minimizer[3] > 0 && Opt2.minimizer[1] > 0 && Opt2.minimizer[2] < 0)\n",
    "                Opt = Opt2;\n",
    "            end;\n",
    "        end;\n",
    "    end;\n",
    "    \n",
    "    return (\n",
    "        Optimisation = Opt,\n",
    "        SEIR_model = model!,\n",
    "        RSS = RSS,\n",
    "        Basic_reproduction = Basic_repr\n",
    "    );\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Performance check\n",
    "# It may make sense to run these once, as it allows Julia to precompile these functions\n",
    "# First run usually takes about 30 seconds (on an i5 6500, 4 Threads).\n",
    "@time Estimate_function_Stockholm(p_symp = 0.0127, p_lower_inf = 1, iter = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These are also definied earlier\n",
    "\n",
    "# Rate of leaving incubation\n",
    "eta_value    = 1/5.1;\n",
    "# Rate of recovery\n",
    "gammaD_value = 1/5;\n",
    "\n",
    "## Tolerance for ode and optimisation. \n",
    "Atol = 1e-8;\n",
    "Rtol = 1e-10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Analysis  p_symp_use <- 0.0127\n",
    "# Analysis  p_lower_inf_use <- 1, 0.55, 0.11\n",
    "p_symp_use      = 0.0127\n",
    "p_asymp_use     = 1 - p_symp_use\n",
    "p_lower_inf_use = 3\n",
    "\n",
    "# These are sadly both defined as local vars and here, global vars. Watch out.\n",
    "eta = eta_value;\n",
    "gammaD = gammaD_value;\n",
    "\n",
    "Est_par_model = Estimate_function_Stockholm(p_symp = p_symp_use, p_lower_inf = p_lower_inf_use);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Est = Est_par_model.Optimisation;\n",
    "Opt_par = (;zip(Symbol.(Opt_par_names), values(Est.minimizer))...);\n",
    "Basic_repr = Est_par_model.Basic_reproduction;\n",
    "RSS_value = Est.minimum;\n",
    "\n",
    "H         = hessian(Est_par_model.RSS, [values(Opt_par)...]);\n",
    "sigest    = sqrt(RSS_value/(length(Incidence)-3));\n",
    "NeginvH2  = inv((1/(2*sigest^2)) * H);\n",
    "sdParams  = sqrt.(Diagonal(NeginvH2).diag);\n",
    "\n",
    "#println(\"Est = \", Est)\n",
    "println(\"Opt_par = \", Opt_par)\n",
    "println(\"sdParams = \", sdParams)\n",
    "println(\"RSS_value = \", RSS_value)\n",
    "print(\"Hessian:\")\n",
    "# Rounding just for the sake of printing, as it allows for easier comparison to the R code\n",
    "Int64.(round.(H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prevalence check\n",
    "Look at the results, and compare with prevalence 27th March to 3rd April.\n",
    "\n",
    "Basically this is done in order to verify how reasonable the estimate is. Folkhälsomyndiheten made a [cross-sectional prevalence study](https://www.folkhalsomyndigheten.se/publicerat-material/publikationsarkiv/f/forekomsten-av-covid-19-i-region-stockholm-26-mars3-april-2020/) during this time interval, and concluded that the prevalence at that point was likely 2.5% (95% CI &rarr; 1.4-4.1%). I'm not completely sure whether this takes the sensitivity and specificity of the test into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (Dag[1]):(Dag[length(Dag)]+14+11) # time in days\n",
    "t2 = Float64.((t.start, t.stop)); # same as t, but in a format that the ode solver can deal with\n",
    "\n",
    "# The following code looks very different as compared to the R code. \n",
    "# This is because the ode solver returns what would be the equivalent of the solution function.\n",
    "# We therefore have to extract the values for discrete days in the loop below.\n",
    "# fit <- data.frame(ode(y = init, times = t, func = SEIR_model , parms = Opt_par))\n",
    "\n",
    "fit   = solve(ODEProblem(Est_par_model.SEIR_model, initfa, t2, [Opt_par...]), Tsit5());\n",
    "\n",
    "fit_S       = Vector{Float64}(undef, length(t));\n",
    "fit_E       = Vector{Float64}(undef, length(t));\n",
    "fit_I_symp  = Vector{Float64}(undef, length(t));\n",
    "fit_I_asymp = Vector{Float64}(undef, length(t));\n",
    "fit_R       = Vector{Float64}(undef, length(t));\n",
    "fit_I       = Vector{Float64}(undef, length(t));\n",
    "fit_I_E     = Vector{Float64}(undef, length(t));\n",
    "fit_cum_inf = Vector{Float64}(undef, length(t));\n",
    "\n",
    "for (i, d) in enumerate(t)\n",
    "    fit_S[i] = fit(d)[1];\n",
    "    fit_E[i] = fit(d)[2];\n",
    "    fit_I_symp[i] = fit(d)[3];\n",
    "    fit_I_asymp[i] = fit(d)[4];\n",
    "    fit_R[i] = fit(d)[5];\n",
    "    fit_I = fit_I_symp + fit_I_asymp\n",
    "    fit_I_E = fit_E + fit_I\n",
    "    fit_cum_inf = N .- fit_S\n",
    "end;\n",
    "\n",
    "\n",
    "## The mean prevalence same days as the Hälsorapport Stockholmsstudien (27th March to 3rd April)\n",
    "Smittsamma  = fit_I_symp + fit_I_asymp #+ fit_E\n",
    "SmittsammaF =  Smittsamma[40:47]\n",
    "println(\"Medelprevalens 27/3-3/4: \", round(mean(SmittsammaF/N)*100, digits = 3), \"%\")\n",
    "\n",
    "## Look at the estimated reported cases and fitted\n",
    "\n",
    "fitted_incidence = p_symp_use * fit_E * eta;\n",
    "#fitted_incidence_non_report = (1 - p_symp_use) * fit_E * eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting engine\n",
    "#GR();\n",
    "plotly(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(Datum, Incidence, label = \"Reported cases\", marker = (:circle, :white), line = (:black));\n",
    "plot!(dayToDate.(t), fitted_incidence, label = \"Fitted reported cases\", line = (2, 0.7, :blue))\n",
    "plot!(legend = :topleft, xlabel = \"Day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at the estimated infectivity and basic reproductive number\n",
    "## 1 jan, 1 feb  osv\n",
    "dayatyear_march_april = [1, 32, 61, 61 + 31, 61 + 31 + 30, 61 + 31 + 30 + 31];\n",
    "NameDateMarchApril = dayToDate.(dayatyear_march_april);\n",
    "# par(mfrow = c(1,2), mar = c(6.1, 4.1, 6.1, 5.1)) # Not translated\n",
    "plot(dayToDate.(0:150),\n",
    "    Basic_repr.(0:150, Opt_par..., gammaD),\n",
    "    ylabel = \"R0(t)\",\n",
    "    title  = \"Estimated reproductive number\",\n",
    "    label = \"R0\",\n",
    "    legend = false,\n",
    "    line = (1.5, :black)\n",
    "    );\n",
    "p1 = vline!([Datum[1], Datum[end]], line = (:dash, :gray))\n",
    "\n",
    "plot(dayToDate.(0:150),\n",
    "    beta_decrease.(0:150, Opt_par...),#type=\"l\", ylab=\"Infectivity\",lwd=2, \n",
    "    title = \"Estimated infectivity\",\n",
    "    ylabel = \"Infectivity, symptomatics\",\n",
    "    label = \"Beta(t)\",\n",
    "    legend = false,\n",
    "    line = (1.5, :black)\n",
    ")\n",
    "p2 = vline!([Datum[1], Datum[end]], line = (:dash, :gray));\n",
    "plot(p1, p2, size = (800,400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate results to save in tables\n",
    "In the original code, they denote `delta` as `p`. Note that the minescule differences between this simulation and the original simulation start to add up as we do more and more calculations. These values can deviate as much as about 0.1 from the values in the R simulation, due to a slightly different `Opt_par`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To create bootstrap CI\n",
    "CI_level_05 = 0.025\n",
    "\n",
    "delta_high    = quantile(Normal(Opt_par[1], sdParams[1]), 1-CI_level_05);\n",
    "epsilon_high  = quantile(Normal(Opt_par[2], sdParams[2]), 1-CI_level_05);\n",
    "theta_high    = quantile(Normal(Opt_par[3], sdParams[3]), 1-CI_level_05);\n",
    "\n",
    "delta_low     = max(0, quantile(Normal(Opt_par[1], sdParams[1]), CI_level_05));\n",
    "epsilon_low   = quantile(Normal(Opt_par[2], sdParams[2]), CI_level_05);\n",
    "theta_low     = quantile(Normal(Opt_par[3], sdParams[3]), CI_level_05);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_v   = rand(Normal(Opt_par[1], sdParams[1]), 1000);\n",
    "delta_v   = [max(0, d) for d in delta_v];\n",
    "epsilon_v = rand(Normal(Opt_par[2], sdParams[2]), 1000);\n",
    "theta_v   = rand(Normal(Opt_par[3], sdParams[3]), 1000);\n",
    "\n",
    "# Doesn't have to be initialized, but it's more efficient.\n",
    "# List comprehension is also an option.\n",
    "R0_v_Dag1 = Vector{Float64}(undef, length(delta_v));\n",
    "R0_v_DagSista = Vector{Float64}(undef, length(delta_v));\n",
    "\n",
    "for i in 1:length(delta_v)\n",
    "    R0_v_Dag1[i]      = Basic_repr(Dag[1], delta_v[i], epsilon_v[i], theta_v[i], gammaD) \n",
    "    R0_v_DagSista[i]  = Basic_repr(Dag[end], delta_v[i], epsilon_v[i], theta_v[i], gammaD) \n",
    "end;\n",
    "\n",
    "println(\"CRI-R0_v_Dag1: \", CRI(R0_v_Dag1, level= 0.95))\n",
    "println(\"CRI-R0_v_DagSista: \", CRI(R0_v_DagSista, level= 0.95))\n",
    "\n",
    "R0_low  = [CRI_95_low(R0_v_Dag1), CRI_95_low(R0_v_DagSista)];\n",
    "R0_high = [CRI_95_up(R0_v_Dag1), CRI_95_up(R0_v_DagSista)];\n",
    "\n",
    "R0_Mean = Basic_repr.(Dag, Opt_par..., gammaD);\n",
    "\n",
    "println(\"R0_Mean[1]: \", R0_Mean[1])\n",
    "println(\"R0_Mean[end]: \", R0_Mean[end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save estimated parameters and their SE\n",
    "Files are saved with a `J-` prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_param = [round.((p_asymp_use, p_lower_inf_use), digits = 3)..., round(mean(SmittsammaF / N), digits = 5), round.((RSS_value, Opt_par[1], sdParams[1], Opt_par[2], sdParams[2], Opt_par[3], sdParams[3]), digits = 3)...];\n",
    "# Julia does not allow duplicate names for NamedTuples.\n",
    "res_param_names = [\"p_0\", \"q_0\",\"27 mars - 3 april\", \"RSS\" ,\"delta\", \"s.e.\", \"epsilon\", \"s.e.\", \"theta\", \"s.e.\"]\n",
    "\n",
    "CIdelta   = \"[\" * join(round.([delta_low, delta_high],digits = 3), \",\")   * \"]\";\n",
    "CIepsilon = \"[\" * join(round.([epsilon_low, epsilon_high],digits = 3), \",\") * \"]\";\n",
    "CItheta   = \"[\" * join(round.([theta_low, theta_high],digits = 3), \",\")   * \"]\";\n",
    "\n",
    "CI_param = [\"\", \"\", \"\", \"\", CIdelta, \"\", CIepsilon, \"\", CItheta, \"\"];\n",
    "\n",
    "df_res = DataFrame(Matrix{Any}(undef, 0, 10), Symbol.(res_param_names), makeunique=true);\n",
    "push!(df_res, res_param);\n",
    "push!(df_res, CI_param);\n",
    "\n",
    "df_res |> save(join([\"Results/Tables/\",\"J-Res_para_p_non-reported_\",p_asymp_use,\"_infect_\",p_lower_inf_use,\".xlsx\"]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results with 31 days forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was already calculated at an earlier stage...\n",
    "t = (Dag[1]):(Dag[length(Dag)]+14+11) # time in days\n",
    "t2 = Float64.((t.start, t.stop)); # same as t, but in a format that the ode solver can deal with\n",
    "\n",
    "# The approach is somewhat different to that of the R code, due to a different library.\n",
    "fit         = solve(ODEProblem(Est_par_model.SEIR_model, initfa, t2, [Opt_par...]), Tsit5());\n",
    "fit_S       = Vector{Float64}(undef, length(t));\n",
    "fit_E       = Vector{Float64}(undef, length(t));\n",
    "fit_I_symp  = Vector{Float64}(undef, length(t));\n",
    "fit_I_asymp = Vector{Float64}(undef, length(t));\n",
    "fit_R       = Vector{Float64}(undef, length(t));\n",
    "fit_I       = Vector{Float64}(undef, length(t));\n",
    "fit_I_E     = Vector{Float64}(undef, length(t));\n",
    "fit_cum_inf = Vector{Float64}(undef, length(t));\n",
    "\n",
    "for (i, d) in enumerate(t)\n",
    "    fit_S[i] = fit(d)[1];\n",
    "    fit_E[i] = fit(d)[2];\n",
    "    fit_I_symp[i] = fit(d)[3];\n",
    "    fit_I_asymp[i] = fit(d)[4];\n",
    "    fit_R[i] = fit(d)[5];\n",
    "    fit_I = fit_I_symp + fit_I_asymp\n",
    "    fit_I_E = fit_E + fit_I\n",
    "    fit_cum_inf = N .- fit_S\n",
    "end;\n",
    "\n",
    "\n",
    "fitted_incidence = p_symp_use * fit_E * eta;\n",
    "fitted_incidence_non_report = (1 - p_symp_use) * fit_E * eta;\n",
    "\n",
    "Cum_Inf_inc = DataFrame(\n",
    "    Cumulative = fit_cum_inf,\n",
    "    Incidence_reported = fitted_incidence,\n",
    "    Incidence_non_reported = fitted_incidence_non_report,\n",
    "    Datum = dayToDate.(t)\n",
    ");\n",
    "\n",
    "Cum_Inf_inc = hcat(\n",
    "    DataFrame(time = t, S = fit_S, E = fit_E, I_symp = fit_I_symp, I_asymp = fit_I_asymp, R = fit_R),\n",
    "    Cum_Inf_inc\n",
    ");\n",
    "\n",
    "# Saved as csv here, instead of txt in the original code.\n",
    "Cum_Inf_inc |> save(join([\"Results/Tables/\",\"J-Raw_data_fitted_model\", \"_para_p_asymp\", p_asymp_use, \"infect\", p_lower_inf_use, \".csv\"]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now calculate bootstrap CI's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_S_v       = Matrix{Float64}(undef, length(delta_v), length(t));\n",
    "fit_E_v       = Matrix{Float64}(undef, length(delta_v), length(t));\n",
    "fit_I_symp_v  = Matrix{Float64}(undef, length(delta_v), length(t));\n",
    "fit_I_asymp_v = Matrix{Float64}(undef, length(delta_v), length(t));\n",
    "Fit_I_v       = Matrix{Float64}(undef, length(delta_v), length(t));\n",
    "fit_cum_inf_v = Matrix{Float64}(undef, length(delta_v), length(t));\n",
    "\n",
    "fitted_incidence_v = Matrix{Float64}(undef, length(delta_v), length(t));\n",
    "effective_reprod_v = Matrix{Float64}(undef, length(delta_v), length(t));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i = 1:length(delta_v)\n",
    "    Opt_parDummy = (delta = delta_v[i], epsilon = epsilon_v[i], theta = theta_v[i]);\n",
    "    fitDummy     = solve(ODEProblem(Est_par_model.SEIR_model, initfa, t2, [Opt_parDummy...]), Tsit5());\n",
    "    \n",
    "    for (r, d) in enumerate(t)\n",
    "        fit_S_v[i, r] = fitDummy(d)[1];\n",
    "        fit_E_v[i, r] = fitDummy(d)[2];\n",
    "        fit_I_symp_v[i, r] = fitDummy(d)[3];\n",
    "        fit_I_asymp_v[i, r] = fitDummy(d)[4];\n",
    "        Fit_I_v[i, r] = fitDummy(d)[3] + fitDummy(d)[4];\n",
    "        fit_cum_inf_v[i, r] = N - fitDummy(d)[1];\n",
    "    end;\n",
    "\n",
    "    fitted_incidence_v[i, :] = p_symp_use *  fit_E_v[i, :] * eta;\n",
    "    #fitted_incidence.v[i,] <- beta(fitDummy[,1], delta = Opt_parDummy[1], epsilon = Opt_parDummy[2], theta = Opt_parDummy[3]) * fitDummy[ , 2] *  fitDummy[ , 4]/N \n",
    "    effective_reprod_v[i, :] = @. Basic_repr(t, Opt_parDummy..., gammaD) * fit_S_v[i, :] / N;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_inf_mean       = mean(fit_cum_inf_v, dims = 1);\n",
    "cum_inf_median     = median(fit_cum_inf_v, dims = 1);\n",
    "cum_inf_95_up_CRI  = [CRI_95_up(col) for col in eachcol(fit_cum_inf_v)];\n",
    "cum_inf_95_low_CRI = [CRI_95_low(col) for col in eachcol(fit_cum_inf_v)];\n",
    "\n",
    "fit_I_mean       = mean(Fit_I_v, dims = 1);\n",
    "fit_I_median     = median(Fit_I_v, dims = 1);\n",
    "fit_I_95_up_CRI  = [CRI_95_up(col) for col in eachcol(Fit_I_v)];\n",
    "fit_I_95_low_CRI = [CRI_95_low(col) for col in eachcol(Fit_I_v)];\n",
    "\n",
    "fitted_Incidence_mean       = mean(fitted_incidence_v, dims = 1);\n",
    "fitted_Incidence_median     = median(fitted_incidence_v, dims = 1);\n",
    "fitted_Incidence_95_up_CRI  = [CRI_95_up(col) for col in eachcol(fitted_incidence_v)];\n",
    "fitted_Incidence_95_low_CRI = [CRI_95_low(col) for col in eachcol(fitted_incidence_v)];\n",
    "\n",
    "effective_reprod_mean       = mean(effective_reprod_v, dims = 1);\n",
    "effective_reprod_median     = median(effective_reprod_v, dims = 1);\n",
    "effective_reprod_95_up_CRI  = [CRI_95_up(col) for col in eachcol(effective_reprod_v)];\n",
    "effective_reprod_95_low_CRI = [CRI_95_low(col) for col in eachcol(effective_reprod_v)];\n",
    "\n",
    "# Cummulative number of infected until 2020-04-11 and until 2020-05-01, with their 95% CI\n",
    "# 2020-04-11 = dag 102\n",
    "# 2020-05-01 = dag 122\n",
    "\n",
    "println(\"Dag 102: \", dayToDate(102));\n",
    "println(\"Dag 122: \", dayToDate(122));\n",
    "\n",
    "println.(vcat([[\n",
    "fit_cum_inf[t.==d][1],\n",
    "cum_inf_95_low_CRI[t.==d][1],\n",
    "cum_inf_95_up_CRI[t.==d][1],\n",
    "\n",
    "fit_cum_inf[t.==d][1]/N,\n",
    "cum_inf_95_low_CRI[t.==d][1]/N,\n",
    "cum_inf_95_up_CRI[t.==d][1]/N,\n",
    "\"\"] for d in [102, 122]]...));\n",
    "\n",
    "maxdagen = dayToDate(t[fit_I .== maximum(fit_I)][1]);\n",
    "minDag   = dayToDate(t[fit_I_95_low_CRI .== maximum(fit_I_95_low_CRI)][1]);\n",
    "maxDag   = dayToDate(t[fit_I_95_up_CRI .== maximum(fit_I_95_up_CRI)][1]);\n",
    "\n",
    "println.([maxdagen, minDag, maxDag]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save estimated R0 and their uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_R0       = round.([p_asymp_use, p_lower_inf_use, R0_Mean[1], R0_Mean[length(Dag)], effective_reprod_mean[length(Dag)]], digits = 3);\n",
    "res_R0_names = [\"p_0\", \"q_0\", \"R0(start)\", \"R0(end)\", \"Re(end)\"];\n",
    "CI_R01       = join([\"[\",round(R0_low[1], digits=3), \", \", round(R0_high[1], digits=3),\"]\"]);\n",
    "CI_ROend     = join([\"[\",round(R0_low[2], digits=3), \", \", round(R0_high[2], digits=3),\"]\"]);\n",
    "CI_Reend     = join([\"[\",round(effective_reprod_95_low_CRI[length(Dag)],digits=3), \", \", round(effective_reprod_95_up_CRI[length(Dag)],digits=3),\"]\"]);\n",
    "CIR0         = [\"\", \"\", CI_R01, CI_ROend,CI_Reend];\n",
    "\n",
    "df_resR0 = DataFrame(Matrix{Any}(undef, 0, 5), Symbol.(res_R0_names), makeunique=true);\n",
    "push!(df_resR0, res_R0);\n",
    "push!(df_resR0, CIR0);\n",
    "\n",
    "df_resR0 |> save(join([\"Results/Tables/\",\"J-Res_R0_p_non-reported_\", p_asymp_use, \"_infect_\", p_lower_inf_use, \".xlsx\"]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save estimated days and their CI\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
